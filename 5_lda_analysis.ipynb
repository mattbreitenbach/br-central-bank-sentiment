{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffe7196",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA) Topic Modeling\n",
    "\n",
    "This notebook is dedicated to Latent Dirichlet Allocation (LDA), a technique to discover the abstract \"topics\".\n",
    " * LDA is often used to categoryzed documents, but in this context it will categorize paragraphs.\n",
    " * The script applies LDA (gensim) to identify recurring themes across the minutes.\n",
    " * The number of topics (n_components), is set to 6. This decision was taken on appendix, notebook 5.1. \n",
    " * The script also displays the most significant words for each of these identified topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92948d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a468f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_info = pd.read_excel(\"./data/raw/minutes_info.xlsx\")\n",
    "\n",
    "FOLDER_MINUTES_LEMMATIZED = \"./data/processed/copom_minutes_lemmatized\"\n",
    "FOLDER_MINUTES_NOT_LEMMATIZED = \"./data/processed/copom_minutes_not_lemmatized\"\n",
    "INITIAL_DATE = \"2003-06-26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95070fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_info = pd.read_excel(\"./data/raw/minutes_info.xlsx\")\n",
    "minutes_info['DataReferencia'] = pd.to_datetime(minutes_info['DataReferencia'])\n",
    "minutes_info = minutes_info[minutes_info[\"DataReferencia\"] >= INITIAL_DATE]\n",
    "\n",
    "minutes_names = minutes_info[\"Titulo\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb6a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_with_metadata = []\n",
    "all_docs_for_lda = []\n",
    "\n",
    "\n",
    "for minute in minutes_names:\n",
    "    lemm_minute_path = f\"{FOLDER_MINUTES_LEMMATIZED}/{minute}.txt\"\n",
    "    not_lemm_minute_path = f\"{FOLDER_MINUTES_NOT_LEMMATIZED}/{minute}.txt\"\n",
    "\n",
    "    with open(lemm_minute_path, 'r', encoding='utf-8') as f:\n",
    "        lemm_paragraphs = [line.split() for line in f.readlines()]\n",
    "\n",
    "    with open(not_lemm_minute_path, 'r', encoding='utf-8') as f:\n",
    "        not_lemm_paragraphs = [line.split() for line in f.readlines()]\n",
    "\n",
    "    if len(lemm_paragraphs) == len(not_lemm_paragraphs):\n",
    "        lemm_paragraphs_final = []\n",
    "        not_lemm_paragraphs_final = []\n",
    "        for i in range(len(lemm_paragraphs)):\n",
    "            if len(lemm_paragraphs[i]) > 5:\n",
    "                lemm_paragraphs_final.append(lemm_paragraphs[i])\n",
    "                not_lemm_paragraphs_final.append(not_lemm_paragraphs[i])\n",
    "\n",
    "        if len(lemm_paragraphs_final) != len(not_lemm_paragraphs_final):\n",
    "            print(f\"Error 2 in: {minute}\")\n",
    "\n",
    "        for i in range(len(lemm_paragraphs_final)):\n",
    "            all_docs_with_metadata.append({'original_text': not_lemm_paragraphs_final[i], 'lemm_text': lemm_paragraphs_final[i], 'minute': minute})\n",
    "            all_docs_for_lda.append(lemm_paragraphs_final[i])\n",
    "\n",
    "    else:\n",
    "        print(f\"Error in: {minute}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900779a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(all_docs_for_lda)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in all_docs_for_lda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60015880",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 6\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=NUM_TOPICS,\n",
    "                     random_state=100,\n",
    "                     passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea098ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"employment\" + 0.029*\"increase\" + 0.021*\"real\" + 0.020*\"accord\" + 0.019*\"rate\" + 0.019*\"job\" + 0.018*\"month\" + 0.018*\"year\" + 0.018*\"compare\" + 0.017*\"thousand\"')\n",
      "(1, '0.065*\"rate\" + 0.041*\"inflation\" + 0.034*\"price\" + 0.025*\"projection\" + 0.024*\"meeting\" + 0.022*\"scenario\" + 0.021*\"copom\" + 0.018*\"exchange\" + 0.017*\"increase\" + 0.017*\"target\"')\n",
      "(2, '0.068*\"billion\" + 0.053*\"u\" + 0.030*\"operation\" + 0.023*\"total\" + 0.023*\"credit\" + 0.022*\"reach\" + 0.020*\"month\" + 0.019*\"average\" + 0.018*\"increase\" + 0.017*\"export\"')\n",
      "(3, '0.018*\"growth\" + 0.017*\"economy\" + 0.014*\"economic\" + 0.013*\"market\" + 0.012*\"demand\" + 0.011*\"activity\" + 0.010*\"domestic\" + 0.010*\"international\" + 0.009*\"high\" + 0.009*\"recovery\"')\n",
      "(4, '0.042*\"increase\" + 0.028*\"month\" + 0.027*\"price\" + 0.020*\"good\" + 0.015*\"production\" + 0.014*\"industrial\" + 0.014*\"compare\" + 0.013*\"inflation\" + 0.013*\"sale\" + 0.012*\"index\"')\n",
      "(5, '0.057*\"inflation\" + 0.034*\"monetary\" + 0.028*\"policy\" + 0.023*\"copom\" + 0.018*\"committee\" + 0.016*\"risk\" + 0.016*\"target\" + 0.015*\"scenario\" + 0.012*\"rate\" + 0.012*\"expectation\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d2b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Organizar os resultados em um DataFrame\n",
    "def get_dominant_topic(doc_bow, lda_model):\n",
    "    topic_dist = lda_model.get_document_topics(doc_bow)\n",
    "    dominant_topic = sorted(topic_dist, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    return dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8564f67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             minute  \\\n",
      "0  271st Meeting - June 17-18, 2025   \n",
      "1  271st Meeting - June 17-18, 2025   \n",
      "2  271st Meeting - June 17-18, 2025   \n",
      "3  271st Meeting - June 17-18, 2025   \n",
      "4  271st Meeting - June 17-18, 2025   \n",
      "\n",
      "                                       original_text  \\\n",
      "0  1. The global environment remains adverse and ...   \n",
      "1  2. In addition, the behavior and the volatilit...   \n",
      "2  3. Regarding the domestic scenario, the set of...   \n",
      "3  4. In recent releases, headline inflation and ...   \n",
      "4  5. The inflation outlook remains challenging i...   \n",
      "\n",
      "                                           lemm_text  dominant_topic  \n",
      "0  global environment remain adverse particularly...               3  \n",
      "1  addition behavior volatility different asset c...               3  \n",
      "2  regard domestic scenario set indicator economi...               3  \n",
      "3  recent release headline inflation measure unde...               1  \n",
      "4  inflation outlook remain challenge several dim...               5  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# Itera sobre a lista que contém os metadados\n",
    "for i, doc_info in enumerate(all_docs_with_metadata):\n",
    "    doc_bow = corpus[i] # Pega o BoW correspondente pelo índice\n",
    "    dominant_topic = get_dominant_topic(doc_bow, lda_model)\n",
    "    results.append({\n",
    "        'minute': doc_info['minute'], # Adiciona o nome do arquivo\n",
    "        'original_text': ' '.join(doc_info['original_text']),\n",
    "        'lemm_text': ' '.join(doc_info['lemm_text']),\n",
    "        'dominant_topic': dominant_topic\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_excel('./data/processed/lda_results.xlsx', index=False)\n",
    "print(df_results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
