{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0e7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz #PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2807d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_RAW = \"./data/raw\"\n",
    "FOLDER_PROCESSED = \"./data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc50ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_HEADER_MARKERS = {4: \"Copom Meeting\",\n",
    "                        5: \"bcb.gov.br\"}\n",
    "NOISE_FOOTER_MARKERS = {2: [\"exchange policy actions. Questions and comments to gci.bacen@bcb.gov.br\", \"Information for unrestricted disclosure. It is not intended to \"]}\n",
    "\n",
    "INITIAL_TEXT_MARKERS = {\n",
    "    1: [\"THE BOARD ANALYZED THE RECENT PERFORMANCE \", \"THE BOARD ANALYZED THE RECENT EVOLUTION \"],\n",
    "    2: [\"THE BOARD ANALYZED THE RECENT PERFORMANCE \"],\n",
    "    3: [\"THE MEMBERS OF THE COPOM ANALYZED \", \"THE MEMBERS OF THE MONETARY POLICY \"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce565d41",
   "metadata": {},
   "source": [
    "#### CODE INCOMPLETE\n",
    "This code is incomplete and requires further work. I shall return to it in the future.\n",
    "- Some .PDF files could not be converted to text properly due to encoding problems. E.g., \"7 K H \u0003 % R D U G \u0003 D Q D O\";\n",
    "- Some Minutes that i shall manually adjust: All Version 1 (43->60)... 61, 69... 80, 81, 82... 201, 207, 208."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b08829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_2_text(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file using PyMuPDF (fitz).\n",
    "\n",
    "    Parameters:\n",
    "     - file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "     - List[str]: A list of strings, each representing the text extracted from a single page of the .PDF file.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    texts = []\n",
    "    for page in doc:\n",
    "        texts.append(page.get_text())\n",
    "    doc.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6710de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_page_header_by_noise_marker(page: str, marker: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove the page header, using a noise text marker, and returning all the content after the header.\n",
    "\n",
    "    Args:\n",
    "     - page (str): The page text.\n",
    "     - marker (str): The text marker that shows the end of the header.\n",
    "     \n",
    "    Return:\n",
    "     - str: Page text without the header.\n",
    "    \"\"\"\n",
    "    start_index = page.find(marker)\n",
    "    if start_index == -1:\n",
    "        raise ValueError(f\"ERROR finding the marker: '{marker}' on the page.\")\n",
    "    return page[start_index + len(marker):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82f2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_page_footer_by_noise_marker(page: str, marker: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove the page footer, using a noise text marker, and returning all the content before the footer.\n",
    "\n",
    "    Args:\n",
    "     - page (str): The page text.\n",
    "     - marker (str): The text marker that shows the start of the footer.\n",
    "     \n",
    "    Return:\n",
    "     - str: Page text without the header.\n",
    "    \"\"\"\n",
    "    end_index = page.find(marker)\n",
    "    if end_index == -1:\n",
    "        return page\n",
    "        #raise ValueError(f\"ERROR finding the marker: '{marker}' on the page.\")\n",
    "    return page[:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2ae13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_start_of_content(page: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the start of the main content on a page, assuming there is no noise header above header.\n",
    "    The logic assumes that the header ends with the first line that is not followed by a whitespace, indicating the start of a paragraph.\n",
    "    This method is not perfect, but does most of the job.\n",
    "    \n",
    "    Args:\n",
    "     - page (str): The page text.\n",
    "     \n",
    "    Retorna:\n",
    "     - str: Page text without the header.\n",
    "    \"\"\"\n",
    "    current_pos = 0\n",
    "\n",
    "    while current_pos < len(page):\n",
    "        newline_pos = page.find('\\n', current_pos) # Finds the next line break.\n",
    "        if newline_pos == -1:\n",
    "            return page[current_pos:]\n",
    "\n",
    "        if page[newline_pos:newline_pos + 2] != \"\\n \":\n",
    "            return page[newline_pos + 1:]\n",
    "        \n",
    "        current_pos = newline_pos + 1\n",
    "        \n",
    "    return \"\" # Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a384de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_footnotes_from_minute(page_text: str, minute_version: int) -> str:\n",
    "    \"\"\"\n",
    "    Processes text to remove the footnotes from the main content, for Copom Minute Version 4.\n",
    "    The footnote detection assumes the note's number will have a maximum of 2 digits.\n",
    "\n",
    "    Args:\n",
    "     - page_text (str): The text content extracted from a single page of the PDF.\n",
    "     - minute_version (int): The format version of the Copom minute.\n",
    "     \n",
    "    Returns:\n",
    "     - wo_footnote_main_text (str): The main text, without footnotes.\n",
    "    \"\"\"   \n",
    "    if minute_version == 4:\n",
    "        footnote_pattern = re.compile(r'\\d{1,2}\\s{0,2}[A-Z][^.\\n]*\\.')\n",
    "        page_text = re.sub(footnote_pattern, \"\", repr(page_text))\n",
    "        return eval(page_text)\n",
    "\n",
    "    elif minute_version == 5:\n",
    "        footnote_pattern = re.compile(r'^\\s*\\d{1,2}\\s+(?![.])', re.MULTILINE)\n",
    "\n",
    "        half_index = int(len(page_text)/2)\n",
    "        page_text_1 = page_text[:half_index]\n",
    "        page_text_2 = page_text[half_index:]\n",
    "\n",
    "        match = footnote_pattern.search(page_text_2)\n",
    "        if match:\n",
    "            return page_text_1 + page_text_2[:match.start()]\n",
    "        else:\n",
    "            return page_text\n",
    "        \n",
    "    else:\n",
    "        return page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7d6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_for_perfect_segregation(texts_pages: List[str], minute_version: int) -> List[str]:\n",
    "    \"\"\"Extract text from pages, when there is perfect segregation. It means, when the start of the content is in a segregated page.\"\"\"\n",
    "\n",
    "    if minute_version == 1:\n",
    "        # No need for processing. This only applies for minute version 1 with perfect segregation.\n",
    "        return texts_pages\n",
    "\n",
    "    header_noise_marker = NOISE_HEADER_MARKERS.get(minute_version)\n",
    "    if not header_noise_marker:\n",
    "        raise ValueError(f\"Noise header marker not found for this file version: {minute_version}\")\n",
    "    \n",
    "    processed_pages = []\n",
    "\n",
    "    for page in texts_pages:\n",
    "        page = page.replace('\\xa0', ' ')\n",
    "        if minute_version == 4:\n",
    "            page_wo_footnote = _remove_footnotes_from_minute(page, minute_version)\n",
    "            header_removed = _remove_page_header_by_noise_marker(page_wo_footnote, header_noise_marker)\n",
    "            content = _find_start_of_content(header_removed)\n",
    "        else:\n",
    "            page_wo_footnote = _remove_footnotes_from_minute(page, minute_version)\n",
    "            content = _remove_page_header_by_noise_marker(page_wo_footnote, header_noise_marker)\n",
    "\n",
    "        processed_pages.append(content)\n",
    "        \n",
    "    return processed_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3be5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_for_imperfect_segregation(texts_pages: List[str], minute_version: int) -> List[str]:\n",
    "    \"\"\"Extract text from pages, when there is IMperfect segregation.\"\"\"\n",
    "    \n",
    "    processed_pages = []\n",
    "    \n",
    "    first_page = texts_pages[0].replace('\\xa0', ' ')\n",
    "    first_page_upper = first_page.upper()\n",
    "    start_index = -1\n",
    "\n",
    "    initial_text_markers = INITIAL_TEXT_MARKERS.get(minute_version)\n",
    "    if not initial_text_markers:\n",
    "        raise ValueError(f\"Initial text marker not found FOR this file version: {minute_version}\")\n",
    "\n",
    "    for marker in initial_text_markers:\n",
    "        start_index = first_page_upper.find(marker)\n",
    "        if start_index != -1:\n",
    "            break\n",
    "    if start_index == -1:\n",
    "        raise ValueError(f\"Initial text marker not found IN this file version: {minute_version}\")\n",
    "    \n",
    "    footer_noise_marker = NOISE_FOOTER_MARKERS.get(minute_version)\n",
    "    if not footer_noise_marker:\n",
    "        pass\n",
    "        #raise ValueError(f\"Noise footer marker not found for this file version: {minute_version}\")\n",
    "    \n",
    "    first_page_content = first_page[start_index:]\n",
    "    if footer_noise_marker:\n",
    "        for footer_marker in footer_noise_marker:\n",
    "            first_page_content = _remove_page_footer_by_noise_marker(first_page_content, footer_marker)\n",
    "\n",
    "    processed_pages.append(first_page_content)\n",
    "    \n",
    "    for page in texts_pages[1:]:\n",
    "        cleaned_page = page.replace('\\xa0', ' ')\n",
    "        content = _find_start_of_content(cleaned_page)\n",
    "\n",
    "        if footer_noise_marker:\n",
    "            for footer_marker in footer_noise_marker:\n",
    "                content = _remove_page_footer_by_noise_marker(content, footer_marker)\n",
    "    \n",
    "        processed_pages.append(content)\n",
    "        \n",
    "    return processed_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55541f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_paragraphs_breaks(extracted_text: str, minute_version: int) -> str:\n",
    "    \"\"\"\n",
    "    Adjusts the text extracted from a document, such as the Copom minutes, by removing improper line breaks within paragraphs.\n",
    "\n",
    "    The function identifies the start of a new paragraph (e.g., \"1. \", \"A) \", \"(i) \")\n",
    "    and joins the subsequent lines into a single paragraph until a new marker is found.\n",
    "\n",
    "    Args:\n",
    "     - extracted_text (str): The full content of the text extracted from the PDF.\n",
    "\n",
    "    Returns:\n",
    "     - str: The formatted text with corrected paragraphs, separated by a blank line.\n",
    "    \"\"\"\n",
    "    if minute_version == 1:\n",
    "        paragraph_start_pattern = re.compile(r'(?:\\n\\s*)+')\n",
    "        \n",
    "        paragraphs = re.split(paragraph_start_pattern, extracted_text.strip())\n",
    "        formatted_paragraphs = [\" \".join(p.splitlines()) for p in paragraphs if p.strip()]\n",
    "\n",
    "        paragrafos_corrigidos = [formatted_paragraphs[0]]\n",
    "        for p in formatted_paragraphs[1:]:\n",
    "            if (p and p[0].islower()) or (p and p[0].isdigit()):\n",
    "                paragrafos_corrigidos[-1] += \" \" + p\n",
    "            else:\n",
    "                paragrafos_corrigidos.append(p)\n",
    "\n",
    "        return \"\\n\\n\".join(paragrafos_corrigidos)\n",
    "\n",
    "    elif minute_version == 2:\n",
    "        paragraph_start_pattern = re.compile(r'(?:\\n\\s*){2,}')\n",
    "    \n",
    "        paragraphs = re.split(paragraph_start_pattern, extracted_text.strip())\n",
    "        formatted_paragraphs = [\" \".join(p.splitlines()) for p in paragraphs if p.strip()]\n",
    "\n",
    "        paragrafos_corrigidos = [formatted_paragraphs[0]]\n",
    "        for p in formatted_paragraphs[1:]:\n",
    "            if p and p[0].islower():\n",
    "                paragrafos_corrigidos[-1] += \" \" + p\n",
    "            else:\n",
    "                paragrafos_corrigidos.append(p)\n",
    "\n",
    "        return \"\\n\\n\".join(paragrafos_corrigidos)\n",
    "    \n",
    "    elif minute_version == 3:\n",
    "        paragraph_start_pattern = re.compile(r'^\\s*(\\d{1,2}\\.(?!\\d)\\s*|[A-Z][a-z]+(?: \\S+){1,5}\\s*$)', re.MULTILINE)\n",
    "\n",
    "        lines = extracted_text.splitlines()\n",
    "        corrected_paragraphs = []\n",
    "        current_paragraph = []\n",
    "        is_first_line = True\n",
    "\n",
    "        for line in lines:\n",
    "            clean_line = line.strip()\n",
    "\n",
    "            if not clean_line:\n",
    "                continue\n",
    "\n",
    "            if is_first_line or paragraph_start_pattern.match(clean_line):\n",
    "                is_first_line = False\n",
    "                if current_paragraph:\n",
    "                    full_paragraph = \" \".join(current_paragraph)\n",
    "                    corrected_paragraphs.append(full_paragraph)\n",
    "                    \n",
    "                current_paragraph = [clean_line]\n",
    "            else:\n",
    "                if current_paragraph:\n",
    "                    current_paragraph.append(clean_line)\n",
    "\n",
    "        if current_paragraph:\n",
    "            full_paragraph = \" \".join(current_paragraph)\n",
    "            corrected_paragraphs.append(full_paragraph)\n",
    "\n",
    "        return \"\\n\\n\".join(corrected_paragraphs)\n",
    "    \n",
    "    \n",
    "    elif minute_version == 4 or minute_version == 5:\n",
    "        paragraph_start_pattern = re.compile(r'^\\s*(\\d+\\.\\s|[A-Z]\\)\\s|\\([ivx]+\\)\\s)')\n",
    "        lines = extracted_text.splitlines()\n",
    "        corrected_paragraphs = []\n",
    "        current_paragraph = []\n",
    "\n",
    "        for line in lines:\n",
    "            clean_line = line.strip()\n",
    "\n",
    "            if not clean_line:\n",
    "                continue\n",
    "\n",
    "            if paragraph_start_pattern.match(clean_line):\n",
    "                if current_paragraph:\n",
    "                    full_paragraph = \" \".join(current_paragraph)\n",
    "                    corrected_paragraphs.append(full_paragraph)\n",
    "                    \n",
    "                current_paragraph = [clean_line]\n",
    "            else:\n",
    "                if current_paragraph:\n",
    "                    current_paragraph.append(clean_line)\n",
    "\n",
    "        if current_paragraph:\n",
    "            full_paragraph = \" \".join(current_paragraph)\n",
    "            corrected_paragraphs.append(full_paragraph)\n",
    "\n",
    "        return \"\\n\\n\".join(corrected_paragraphs)\n",
    "    \n",
    "    else:\n",
    "        return extracted_text # Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eba1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_minute_from_text(texts_pages: List[str], minute_version: int, perfect_segregation: bool, initial_page: int) -> str:\n",
    "    \"\"\"\n",
    "    Extract the Copom minute text from the list of text of each page of the .pdf file.\n",
    "    \n",
    "    Parameters:\n",
    "     - texts_pages (List[str]): List of strings, each representing the text of a page.\n",
    "     - minute_version (int): The format version of the Copom minute.\n",
    "     - perfect_segregation (bool): If True, consider that the minute starts at a specific page, without unrellated topic above it.\n",
    "     - initial_page (int): The page number where the minute starts.\n",
    "\n",
    "    Returns:\n",
    "     - str: The extracted Copom minute text.\n",
    "    \"\"\"\n",
    "\n",
    "    relevant_pages = texts_pages[initial_page - 1:]\n",
    "\n",
    "    if not relevant_pages: # error\n",
    "        return \"\" \n",
    "\n",
    "    if perfect_segregation:\n",
    "        processed_pages = _extract_for_perfect_segregation(relevant_pages, minute_version)\n",
    "    else:\n",
    "        processed_pages = _extract_for_imperfect_segregation(relevant_pages, minute_version)\n",
    "    \n",
    "    copom_minute_text = \"\\n\".join(processed_pages)\n",
    "    copom_minute_text = adjust_paragraphs_breaks(copom_minute_text, minute_version)\n",
    "    \n",
    "    # Romoving 'Acronyms'\n",
    "    copom_minute_text = copom_minute_text.split(\"Acronyms\", 1)[0]\n",
    "\n",
    "    return copom_minute_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minutes_format = pd.read_excel(f\"{FOLDER_RAW}/minutes_format.xlsx\")\n",
    "for index, row in df_minutes_format.iterrows():\n",
    "    if row.Ignore == 1:\n",
    "        continue\n",
    "    minute_version = row.Version\n",
    "    perfect_segregation = row.PerfSeg\n",
    "    initial_page = row.InitialPage\n",
    "\n",
    "    texts_pages = pdf_2_text(f\"{FOLDER_RAW}/copom_minutes_raw/{row.Titulo}.pdf\")\n",
    "    for i in texts_pages:\n",
    "        print(i)\n",
    "\n",
    "    minute_text = extract_minute_from_text(texts_pages, minute_version, perfect_segregation, initial_page)\n",
    "\n",
    "    try:\n",
    "        with open(f\"{FOLDER_PROCESSED}/copom_minutes_processed/{row.Titulo}.txt\", 'w', encoding='utf-8') as f:\n",
    "            f.write(minute_text)\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"[INFO] Error saving {row.Titulo}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
