{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0e7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz #PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce565d41",
   "metadata": {},
   "source": [
    "#### CODE INCOMPLETE\n",
    "This code is incomplete and requires further work. I shall return to it in the future.\n",
    "* Some .PDF files could not be converted to text properly due to encoding problems. E.g., \"7 K H \u0003 % R D U G \u0003 D Q D O\";\n",
    "* The output does not properly divide chapters and paragraphs, which prevents the implementation of Latent Dirichlet Allocation (LDA);\n",
    "* Footnotes are mixed in the middle of the text;\n",
    "* Text is not saved as ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b08829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_2_text(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file using PyMuPDF (fitz).\n",
    "\n",
    "    Parameters:\n",
    "     - file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "     - List[str]: A list of strings, each representing the text extracted from a single page of the PDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    texts = []\n",
    "    for page in doc:\n",
    "        texts.append(page.get_text())\n",
    "    doc.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a73b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_HEADER_MARKERS = {4: \"Copom Meeting\",\n",
    "                        5: \"bcb.gov.br\"}\n",
    "\n",
    "INITIAL_TEXT_MARKERS = {\n",
    "    1: [\"THE BOARD ANALYZED THE RECENT PERFORMANCE \", \"THE BOARD ANALYZED THE RECENT EVOLUTION \"],\n",
    "    2: [\"THE BOARD ANALYZED THE RECENT PERFORMANCE \"],\n",
    "    3: [\"THE MEMBERS OF THE COPOM ANALYZED \", \"THE MEMBERS OF THE MONETARY POLICY \"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6710de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_page_header_by_noise_marker(page: str, marker: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove the page header, using a noise text marker, and returning all the content after the header.\n",
    "\n",
    "    Args:\n",
    "     - page (str): The page text.\n",
    "     - marker (str): The text marker that shows the end of the header.\n",
    "     \n",
    "    Return:\n",
    "     - str: Page text without the header.\n",
    "    \"\"\"\n",
    "    start_index = page.find(marker)\n",
    "    if start_index == -1:\n",
    "        raise ValueError(f\"ERROR finding the marker: '{marker}' on the page.\")\n",
    "    return page[start_index + len(marker):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2ae13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_start_of_content(page: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the start of the main content on a page, assuming there is no noise header above header.\n",
    "    The logic assumes that the header ends with the first line that is not followed by a whitespace, indicating the start of a paragraph.\n",
    "    This method is not perfect, but does most of the job.\n",
    "    \n",
    "    Args:\n",
    "     - page (str): The page text.\n",
    "     \n",
    "    Retorna:\n",
    "     - str: Page text without the header.\n",
    "    \"\"\"\n",
    "    current_pos = 0\n",
    "\n",
    "    while current_pos < len(page):\n",
    "        newline_pos = page.find('\\n', current_pos) # Finds the next line break.\n",
    "        if newline_pos == -1:\n",
    "            return page[current_pos:]\n",
    "\n",
    "        # If the next character is not a whitespace, it is the start of the content.\n",
    "        if page[newline_pos:newline_pos + 2] != \"\\n \":\n",
    "            return page[newline_pos + 1:]\n",
    "        \n",
    "        # Else, continues loop.\n",
    "        current_pos = newline_pos + 1\n",
    "        \n",
    "    return \"\" # Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7d6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_for_perfect_segregation(texts_pages: List[str], minute_version: int) -> List[str]:\n",
    "    \"\"\"Extract text from pages, when there is perfect segregation.\"\"\"\n",
    "\n",
    "    # No need for processing. Only for version 1 with perfect segregation.\n",
    "    if minute_version == 1:\n",
    "        return texts_pages\n",
    "\n",
    "    # Get 'noise header marker'.\n",
    "    noise_marker = NOISE_HEADER_MARKERS.get(minute_version)\n",
    "    if not noise_marker:\n",
    "        raise ValueError(f\"Noise header marker not found for this file version: {minute_version}\")\n",
    "\n",
    "    processed_pages = []\n",
    "\n",
    "    # Process.\n",
    "    for page in texts_pages:\n",
    "        cleaned_page = page.replace('\\xa0', ' ')\n",
    "        if minute_version == 4:\n",
    "            header_removed = _remove_page_header_by_noise_marker(cleaned_page, noise_marker)\n",
    "            content = _find_start_of_content(header_removed)\n",
    "        else:\n",
    "            content = _remove_page_header_by_noise_marker(cleaned_page, noise_marker)\n",
    "        \n",
    "        processed_pages.append(content)\n",
    "        \n",
    "    return processed_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3be5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_for_imperfect_segregation(texts_pages: List[str], minute_version: int) -> List[str]:\n",
    "    \"\"\"Extract text from pages, when there is IMperfect segregation.\"\"\"\n",
    "    \n",
    "    processed_pages = []\n",
    "    \n",
    "    # Process first page.\n",
    "    first_page = texts_pages[0].replace('\\xa0', ' ')\n",
    "    first_page_upper = first_page.upper()\n",
    "    start_index = -1\n",
    "\n",
    "    # Get 'initial text markers' for first page.\n",
    "    initial_text_markers = INITIAL_TEXT_MARKERS.get(minute_version)\n",
    "    if not initial_text_markers:\n",
    "        raise ValueError(f\"Initial text marker not found FOR this file version: {minute_version}\")\n",
    "\n",
    "    # Search 'initial text marker' in the first page.\n",
    "    for marker in initial_text_markers:\n",
    "        start_index = first_page_upper.find(marker)\n",
    "        if start_index != -1:\n",
    "            break\n",
    "    if start_index == -1:\n",
    "        raise ValueError(f\"Initial text marker not found IN this file version: {minute_version}\")\n",
    "        \n",
    "    processed_pages.append(first_page[start_index:])\n",
    "    \n",
    "    # Process next pages.\n",
    "    for page in texts_pages[1:]:\n",
    "        cleaned_page = page.replace('\\xa0', ' ')\n",
    "\n",
    "        content = _find_start_of_content(cleaned_page)\n",
    "        processed_pages.append(content)\n",
    "        \n",
    "    return processed_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eba1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_minute_from_text(texts_pages: List[str], minute_version: int, perfect_segregation: bool, initial_page: int) -> str:\n",
    "    \"\"\"\n",
    "    Extract the Copom minute text from the list of text of each page of the .pdf file.\n",
    "    \n",
    "    Parameters:\n",
    "     - texts_pages (List[str]): List of strings, each representing the text of a page.\n",
    "     - minute_version (int): The format version of the Copom minute.\n",
    "     - perfect_segregation (bool): If True, consider that the minute starts at a specific page, without unrellated topic above it.\n",
    "     - initial_page (int): The page number where the minute starts.\n",
    "\n",
    "    Returns:\n",
    "     - str: The extracted Copom minute text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Adjust the page list index. initial_page is 1 based.\n",
    "    relevant_pages = texts_pages[initial_page - 1:]\n",
    "    \n",
    "    if not relevant_pages: # error\n",
    "        return \"\" \n",
    "\n",
    "    # Run relevant functions.\n",
    "    if perfect_segregation:\n",
    "        processed_pages = _extract_for_perfect_segregation(relevant_pages, minute_version)\n",
    "    else:\n",
    "        processed_pages = _extract_for_imperfect_segregation(relevant_pages, minute_version)\n",
    "    \n",
    "    # Joins all the pages into a single string, separated by newlines.\n",
    "    copom_minute_text = \"\\n\".join(processed_pages)\n",
    "    \n",
    "    return copom_minute_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folder_path = \"./data/copom_minutes_raw\"\n",
    "output_folder_path = \"./data/copom_minutes_texts\"\n",
    "\n",
    "df_minutes_format = pd.read_excel(\"minutes_format.xlsx\")\n",
    "\n",
    "for index, row in df_minutes_format.iterrows():\n",
    "    if row.NeedAdjust == 1:\n",
    "        continue\n",
    "    minute_version = row.Version\n",
    "    perfect_segregation = row.PerfSeg\n",
    "    initial_page = row.InitialPage\n",
    "\n",
    "    texts_pages = pdf_2_text(f\"{raw_folder_path}/{row.Titulo}.pdf\")\n",
    "\n",
    "    minute_text = extract_minute_from_text(texts_pages, minute_version, perfect_segregation, initial_page)\n",
    "\n",
    "    try:\n",
    "        with open(f\"{output_folder_path}/{row.Titulo}.txt\", 'w', encoding='utf-8') as f:\n",
    "            f.write(minute_text)\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"[INFO] Error saving {row.Titulo}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
