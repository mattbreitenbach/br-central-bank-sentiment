{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f155efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a6af7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    \n",
    "    \n",
    "def lemmatize_word(word, lemmatizer):\n",
    "    pos_tag = nltk.pos_tag([word])[0][1]\n",
    "    wordnet_pos = get_wordnet_pos(pos_tag)\n",
    "    return lemmatizer.lemmatize(word, pos=wordnet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loughran_mcdonald_sets(file_path=\"./data/Loughran-McDonald_MasterDictionary_1993-2024.xlsx\"):\n",
    "\n",
    "    lm_df = pd.read_excel(file_path)\n",
    "\n",
    "    lm_df.columns = [col.lower() for col in lm_df.columns]\n",
    "    lm_df['word'] = lm_df['word'].str.lower()\n",
    "\n",
    "    sentiments = [\"positive\", \"negative\", \"uncertainty\"]\n",
    "    results = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for sentiment in sentiments:\n",
    "        words_list = lm_df[lm_df[sentiment] > 0][\"word\"].dropna().tolist()\n",
    "        words_list_lemm = [lemmatize_word(word, lemmatizer) for word in words_list]\n",
    "        results.append(set(words_list_lemm))\n",
    "    \n",
    "    #\"positive\", \"negative\", \"uncertainty\"\n",
    "    return results[0], results[1], results[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d99254a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words, negative_words, uncertain_words = get_loughran_mcdonald_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_sentiments(lemm_text, positive_set, negative_set, uncertain_set):\n",
    "\n",
    "    negation_set = ['no', 'not', 'never', 'none', 'neither', 'nor', 'without']\n",
    "\n",
    "    if not isinstance(lemm_text, str):\n",
    "        return 0, 0, 0, 0\n",
    "        \n",
    "    words = nltk.word_tokenize(lemm_text.lower())\n",
    "    \n",
    "    total_words = len(words)\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    \n",
    "    uncertainty_count = sum(1 for word in words if word in uncertain_set)\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        is_negated = False\n",
    "\n",
    "        if i > 0:\n",
    "            if words[i-1] in negation_set:\n",
    "                is_negated = True\n",
    "\n",
    "        if word in positive_set:\n",
    "            if is_negated:\n",
    "                negative_count += 1\n",
    "            else:\n",
    "                positive_count += 1\n",
    "\n",
    "        elif word in negative_set:\n",
    "            if is_negated:\n",
    "                positive_count += 1 \n",
    "            else:\n",
    "                negative_count += 1\n",
    "    \n",
    "    return total_words, positive_count, negative_count, uncertainty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73bbd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_results = pd.read_excel(\"./data/processed/lda_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01804794",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_total_words = []\n",
    "list_positive_count = []\n",
    "list_negative_count = []\n",
    "list_uncertainty_count = []\n",
    "\n",
    "for index, row in lda_results.iterrows():\n",
    "    lemm_text = row[\"original_text\"]\n",
    "    total_words, positive_count, negative_count, uncertainty_count = analyze_text_sentiments(lemm_text, positive_words, negative_words, uncertain_words)\n",
    "\n",
    "    list_total_words.append(total_words)\n",
    "    list_positive_count.append(positive_count)\n",
    "    list_negative_count.append(negative_count)\n",
    "    list_uncertainty_count.append(uncertainty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb6ecf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_results = lda_results.copy()\n",
    "\n",
    "sentiments_results['total_words'] = list_total_words\n",
    "sentiments_results['positive_count'] = list_positive_count\n",
    "sentiments_results['negative_count'] = list_negative_count\n",
    "sentiments_results['uncertainty_count'] = list_uncertainty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a49c8170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>total_words</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>uncertainty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11103.00</td>\n",
       "      <td>11103.00</td>\n",
       "      <td>11103.00</td>\n",
       "      <td>11103.00</td>\n",
       "      <td>11103.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.20</td>\n",
       "      <td>50.23</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.23</td>\n",
       "      <td>31.46</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.00</td>\n",
       "      <td>351.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dominant_topic  total_words  positive_count  negative_count  \\\n",
       "count        11103.00     11103.00        11103.00        11103.00   \n",
       "mean             3.20        50.23            1.35            1.12   \n",
       "std              2.23        31.46            1.97            1.69   \n",
       "min              0.00         6.00            0.00            0.00   \n",
       "25%              1.00        27.00            0.00            0.00   \n",
       "50%              3.00        43.00            1.00            0.00   \n",
       "75%              5.00        65.00            2.00            2.00   \n",
       "max              7.00       351.00           18.00           25.00   \n",
       "\n",
       "       uncertainty_count  \n",
       "count           11103.00  \n",
       "mean                1.16  \n",
       "std                 1.76  \n",
       "min                 0.00  \n",
       "25%                 0.00  \n",
       "50%                 0.00  \n",
       "75%                 2.00  \n",
       "max                17.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_results.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0681afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_results.to_excel('./data/processed/sentiments_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cf4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
